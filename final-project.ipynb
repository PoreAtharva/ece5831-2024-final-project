{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e362e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ksaks\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db9ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function for VGG16, this function pre-processes the images for VGG_16 model\n",
    "def preprocess_for_VGG_(frame):\n",
    "    frame = cv2.resize(frame, (224, 224))  # Resize for VGG16\n",
    "    frame = frame / 255.0  # Normalize\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea40d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function for InceptionV3, this function pre-processes the images for InceptionV3 model\n",
    "def preprocess_for_inception(frame):\n",
    "    frame = cv2.resize(frame, (299, 299))  # Resize for InceptionV3\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "    frame = preprocess_input(frame)  # Preprocess for InceptionV3\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d22956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split video into frames function\n",
    "def split_video_into_frames(video_path, output_folder):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    interval = fps\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    extracted_frames = []\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % interval == 0:\n",
    "            extracted_frames.append(frame)  # Save frame to list\n",
    "        frame_count += 1\n",
    "\n",
    "    video.release()\n",
    "    return extracted_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e98cd1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get predictions for frames\n",
    "def get_predictions_for_frames(frames, model_Vgg16, model_InceptionV3, weight_a=0.6, weight_b=0.4):\n",
    "    predictions = []\n",
    "    combined_probabilities = []\n",
    "\n",
    "    for frame in frames:\n",
    "        # Preprocess each frame for both models\n",
    "        vgg_frame = preprocess_for_VGG_(frame)\n",
    "        inception_frame = preprocess_for_inception(frame)\n",
    "\n",
    "        # Get predictions from both models\n",
    "        VGG_predictions = model_Vgg16.predict(vgg_frame)\n",
    "        Inception_predictions = model_InceptionV3.predict(inception_frame)\n",
    "\n",
    "        # Combine predictions with weights\n",
    "        combined_prediction = (weight_a * VGG_predictions) + (weight_b * Inception_predictions)\n",
    "        combined_probabilities.append(combined_prediction)\n",
    "        final_prediction = np.argmax(combined_prediction)  # Multi-class classification\n",
    "        predictions.append(final_prediction)\n",
    "\n",
    "    # Calculate the average probabilities across all frames\n",
    "    avg_probabilities = np.mean(combined_probabilities, axis=0)\n",
    "    avg_final_prediction = np.argmax(avg_probabilities)  # Multi-class classification\n",
    "\n",
    "    return predictions, avg_final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f28962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(input_file, model_Vgg16, model_InceptionV3):\n",
    "    # Gradio provides file paths as strings or dictionaries\n",
    "    if isinstance(input_file, dict) and \"name\" in input_file:\n",
    "        file_path = input_file[\"name\"]\n",
    "    elif isinstance(input_file, str):\n",
    "        file_path = input_file\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported input_file format.\")\n",
    "\n",
    "    # Determine if the input is an image or video based on file extension\n",
    "    if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        print(\"Processing an image file.\")\n",
    "\n",
    "        # Read and preprocess the image\n",
    "        img = cv2.imread(file_path)\n",
    "        vgg_frame = preprocess_for_VGG_(img)\n",
    "        inception_frame = preprocess_for_inception(img)\n",
    "\n",
    "        # Get predictions from both models\n",
    "        VGG_predictions = model_Vgg16.predict(vgg_frame)\n",
    "        print(VGG_predictions)\n",
    "        Inception_predictions = model_InceptionV3.predict(inception_frame)\n",
    "        print(Inception_predictions)\n",
    "\n",
    "        # Combine predictions\n",
    "        weight_a = 0.6\n",
    "        weight_b = 0.4\n",
    "        combined_predictions = (weight_a * VGG_predictions) + (weight_b * Inception_predictions)\n",
    "        final_prediction = np.argmax(combined_predictions)\n",
    "\n",
    "        # Map the prediction to \"Fake\" or \"Real\"\n",
    "        result = \"Real\" if final_prediction == 1 else \"Fake\"\n",
    "        return f\"Predicted Class for Image: {result}\"\n",
    "\n",
    "    elif file_path.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "        print(\"Processing a video file.\")\n",
    "\n",
    "        # Extract frames from video\n",
    "        output_folder = \"temp_frames\"\n",
    "        frames = split_video_into_frames(file_path, output_folder)\n",
    "\n",
    "        # Get predictions for all frames\n",
    "        predictions, avg_prediction = get_predictions_for_frames(frames, model_Vgg16, model_InceptionV3)\n",
    "\n",
    "        # Map predictions to \"Fake\" or \"Real\"\n",
    "        frame_results = [\"Real\" if pred == 1 else \"Fake\" for pred in predictions]\n",
    "        avg_result = \"Real\" if avg_prediction == 1 else \"Fake\"\n",
    "\n",
    "        return (f\"Predicted Classes for Video Frames: {frame_results}\\n\"\n",
    "                f\"Averaged Predicted Class for Video: {avg_result}\")\n",
    "\n",
    "    else:\n",
    "        return \"Error: Unsupported file type.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d006d000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ksaks\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ksaks\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained models\n",
    "model_Vgg16 = load_model(r\"C:\\Users\\ksaks\\Downloads\\DATA\\Models\\model_epoch_37-val_loss_0.5412.h5\")\n",
    "model_InceptionV3 = load_model(r\"C:\\Users\\ksaks\\Downloads\\DATA\\Models\\Model_Inception\\Inception_net_epoch_50_loss_0.5707.h5\")    # Get predictions from both models\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4e7e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing an image file.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.00767984]]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "[[0.36978087]]\n"
     ]
    }
   ],
   "source": [
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=lambda input_file: process_input(input_file, model_Vgg16, model_InceptionV3),\n",
    "    inputs=gr.File(label=\"Upload an Image or Video\"),\n",
    "    outputs=gr.Textbox(label=\"Prediction Result\"),\n",
    "    title=\"Image/Video Classification\",\n",
    "    description=\"Upload an image or video. The system will classify the image or extract frames from the video and classify each frame.\"\n",
    ")\n",
    "\n",
    "# Launch Gradio app\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe385e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4837a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
